{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day3_compbio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1VwIpUrpKCe",
        "colab_type": "text"
      },
      "source": [
        "# Day 3: Classification Models\n",
        "\n",
        "On the first day, we got familiar with the dataset, and feature extraction methods. On the second day, we learnt about Factor Models to reduce the dataset's dimensionality. Our goal today is to build a classification model to classify the images into the classes 'active' and 'inactive'.\n",
        "\n",
        "## 1. Loading and Exploring Data\n",
        "Similar to what we did yesterday, we are going to clone the repository to get the data. We added three new files that contain the latent features generated using the factor models from Day 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YiBgX8upFzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/ai4all-sfu/comp-biology-2020.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke9UPeiMBaxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the libraries \n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Loading files we cloned from github \n",
        "embeddings = pd.read_pickle('comp-biology-2020/embeddings.pkl', compression = 'xz')\n",
        "metadata = pd.read_pickle('comp-biology-2020/metadata.pkl', compression = 'xz')\n",
        "\n",
        "#Selecting only the columns 'site_id' and 'disease_condition'\n",
        "metadata = metadata.iloc[:,[0,7]]\n",
        "\n",
        "#Adding the target 'disease_condition' on embeddings dataset and transforming to 0-1 scale\n",
        "embeddings01 = embeddings.set_index('site_id').join(metadata.set_index('site_id'))\n",
        "print(embeddings01.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2l9uc2MvDnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our latent features from yesterday (they are sorted in the same order of the embeddings dataset)\n",
        "pca = np.load('comp-biology-2020/latent_features/pca50.npz')['arr_0']\n",
        "nmf = np.load('comp-biology-2020/latent_features/mf60.npz')['arr_0']\n",
        "aut = np.load('comp-biology-2020/latent_features/a32.npz')['arr_0']\n",
        "\n",
        "print('PCA Dimensions: ',pca.shape, '\\nMF Dimensions: ',nmf.shape, '\\nAutoencoder Dimensions: ',aut.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59Sg7bTyE9qf",
        "colab_type": "text"
      },
      "source": [
        "In the left side, click in 'Files' and 'Upload to Session Storage' as shown in the image below:  \n",
        "![alt text](https://i.imgur.com/oLk88Mu.jpg)\n",
        "\n",
        "Upload the files from yesterday's exercise: 'mypca.npz' and 'mysvd.npz' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHO7VSq0Ebnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the latent features for PCA and MF into variables 'mypca' and 'mymf'\n",
        "mypca = np.load('mypca.npz')['arr_0']\n",
        "mymf = np.load('mymf.npz')['arr_0']\n",
        "\n",
        "#printing the shape/dimensions of the loaded latent features\n",
        "print('My PCA Dimensions: ',mypca.shape, '\\nMy MF Dimensions: ',mymf.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMqQsTNzIgYA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Recall that if the cell is infected with the virus 'SARS-CoV-2', it is 'active'. Or else, it is 'inactive'. \n",
        "\n",
        "Now, let's check the target with the disease condition. Based on the cell image, we want to identify if it is active or inactive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBx1b90RIeUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(embeddings01['disease_condition'].value_counts()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSlNiWiNOjdc",
        "colab_type": "text"
      },
      "source": [
        "To use this information in our classification models, we will transform the values in the column 'disease_condition' into binary values. If the disease condition is active, it will receive the value 1, and if it is inactive, it will receive the value 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q22LWFkDCvMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = embeddings01['disease_condition'].replace({'active':1, 'inactive':0}).tolist() \n",
        "\n",
        "print(embeddings01['disease_condition'].value_counts()) \n",
        "print(\"Before transforming:\" ,embeddings01['disease_condition'][0:5].tolist())\n",
        "print(\"After transforming:\",target[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZK6uekJ6cyC",
        "colab_type": "text"
      },
      "source": [
        "During our analysis, we will also check one specific image to have an idea how the models work. You can see the image below: ![alt text](https://i.imgur.com/0CnrNXp.png)\n",
        "\n",
        "And according to our metadata, this is an 'active' cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWu4MRgX6Epx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata[metadata['site_id']=='VERO-2_2_Z45_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iaf85eGL-Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bulding a dictionary with all the features \n",
        "features = {'PCA': pca, 'MF': nmf, 'Autoencoder':aut, 'MyPCa': mypca, 'MyMF': mymf}\n",
        "\n",
        "indice = embeddings01.index.get_loc('VERO-2_2_Z45_1') \n",
        "features_example = {'PCA': pca[indice], 'MF': nmf[indice], \n",
        "                    'Autoencoder':aut[indice], 'MyPCa': mypca[indice], 'MyMF': mymf[indice]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tV6wnzKPDvC",
        "colab_type": "text"
      },
      "source": [
        "## 2. Classification Models\n",
        "\n",
        "Our task is to classify if a cell image is infected (class 'active') or not (class 'inactive')."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpaMoM9yH76",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We will use sklearn to import our classifiers. The three models we are going to explore are Logistic Regression, KNN Classifier, and Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnIqYLNXoWJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "#from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "seed = 9\n",
        "\n",
        "# variables to hold the results and models' names\n",
        "results = pd.DataFrame(columns=['model', 'features','accuracy_train', 'accuracy_test', 'precision_test', 'recall_test'])\n",
        "active_image_example = pd.DataFrame(columns=['model', 'features','predicted_target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BizhQX1ZJvYd",
        "colab_type": "text"
      },
      "source": [
        "The first model we are going to explore is Logistic Regression. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frzl_8YOyUx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression(random_state=seed)\n",
        "model_name = 'Logistic Regression'\n",
        "\n",
        "for f in features:\n",
        "  #1) Split the features into training and testing set \n",
        "  X_train, X_test, y_train, y_test = train_test_split(features[f],target , test_size=0.3, random_state=seed) \n",
        "\n",
        "  #2) Fit the model (Fitting a model means that you're making your algorithm learn the relationship between predicted values and outcome so that you can predict better)\n",
        "  model = lr.fit(X_train,y_train)\n",
        "\n",
        "  #3) Predict the labels for the training set and testing set\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  #4) Save the results and calculate the accuracy \n",
        "  output = {'model':model_name, \n",
        "            'features':f, \n",
        "            'accuracy_train':accuracy_score(y_train,y_train_pred), \n",
        "            'accuracy_test':accuracy_score(y_test,y_test_pred),\n",
        "            'precision_test':precision_score(y_test,y_test_pred) ,\n",
        "            'recall_test':recall_score(y_test,y_test_pred) }\n",
        "  #append and add to dataframe 'results'          \n",
        "  results = results.append(output,ignore_index=True)\n",
        "  active_image_example = active_image_example.append({'model':model_name, 'features':f, 'predicted_target':model.predict(features_example[f].reshape(1,-1))}, \n",
        "                              ignore_index=True)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC4grgE4Ppw_",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to explore Random Forest. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpe0F8pmPnxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=30, random_state=seed)\n",
        "model_name = 'Random Forest'\n",
        "\n",
        "for f in features:\n",
        "  #1) Split the features into training and testing set \n",
        "  X_train, X_test, y_train, y_test = train_test_split(features[f],target , test_size=0.3, random_state=seed) \n",
        "\n",
        "  #2) Fit the model\n",
        "  model = rf.fit(X_train,y_train)\n",
        "\n",
        "  #3) Predict the labels for the training set and testing set\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  \n",
        "  #4) Save the results and calculate the accuracy \n",
        "  output = {'model':model_name, \n",
        "            'features':f, \n",
        "            'accuracy_train':accuracy_score(y_train,y_train_pred), \n",
        "            'accuracy_test':accuracy_score(y_test,y_test_pred),\n",
        "            'precision_test':precision_score(y_test,y_test_pred) ,\n",
        "            'recall_test':recall_score(y_test,y_test_pred) }\n",
        "  results = results.append(output,ignore_index=True)\n",
        "  active_image_example = active_image_example.append({'model':model_name, 'features':f, 'predicted_target':model.predict(features_example[f].reshape(1,-1))}, \n",
        "                              ignore_index=True)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tnPkGKNpRO",
        "colab_type": "text"
      },
      "source": [
        "### Activity 1: \n",
        "\n",
        "Looking at the results printed, which combination of features + model produces the best results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NLQBgZaQJmi",
        "colab_type": "text"
      },
      "source": [
        "### Activity 2: \n",
        "\n",
        "Can you now fit the KNN by yourself? Explore different 'n_neighbors' to see if it improves the results. \n",
        "\n",
        "HINT: If you run a cell that appends outputs to the 'results' several times, your plot will have multiple entrances for the same feature + model combination. To avoid that and keep on 'results' only the final models, while you are exploring the questions, comment with # the lines: \n",
        "```\n",
        "#results = results.append(output,ignore_index=True) \n",
        "#active_image_example = active_image_example.append({'model':model_name, 'features':f, 'predicted_target':model.predict(features_example[f].reshape(1,-1))},                              ignore_index=True)\n",
        "```\n",
        "and add: \n",
        "\n",
        "```\n",
        "print(output)\n",
        "```\n",
        "After exploring the question and deciding the number of neighbors, add this code again: \n",
        "```\n",
        "results = results.append(output,ignore_index=True) \n",
        "active_image_example = active_image_example.append({'model':model_name, 'features':f, 'predicted_target':model.predict(features_example[f].reshape(1,-1))},                              ignore_index=True)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XE9EXIQF5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=ADD A NUMBER HERE)\n",
        "model_name = 'KNN'\n",
        "\n",
        "#ADD YOUR CODE HERE\n",
        "#HINT: EXPLORE DIFFERENT SIZES OF N_NEIGHBOORS TO CHECK IF IT IMPROVES THE RESULTS\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Run7zb0eY-",
        "colab_type": "text"
      },
      "source": [
        "Let us use a scatter plot to compare the performance of all the three machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47iAtp2o7Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the comparison using seaborn which is a data visualization library\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "#We had appended the model names and the corresponding features in the dataframe 'results', so we will use that for the plot.\n",
        "\n",
        "#Converting the column \"model\" in dataframe 'results', to datatype 'category'\n",
        "results[\"model\"] = results[\"model\"].astype('category')\n",
        "results[\"features\"] = results[\"features\"].astype('category')\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('\\nComparison of performance between the three ML algorithms') #title of the figure\n",
        "ax = sns.scatterplot(x=\"accuracy_train\", y=\"accuracy_test\", hue=\"model\", style=\"features\", data=results, s = 80) #building scatterplot, and setting values for x-axis and y-axis, hue will group the variables to display different kinds of dots in the plot for the different models, style will produce points with different markers for the different models\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.) #setting a legend for the plot\n",
        "plt.xlabel('Accuracy - Training Set')\n",
        "plt.ylabel('Accuracy - Testing Set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGmHKnBNaU5Z",
        "colab_type": "text"
      },
      "source": [
        "The autoencoder features seem to have worse results. Let's try to remove it and make our plot again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTVasmgjad9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove the autoencoder features from the results dataframe\n",
        "results_without_autoencoder = results[results['features']!='Autoencoder']\n",
        "#again convert the columns 'model' and 'features' in the new dataframe 'results_without_encoder' to categorical datatype to generate the plot.\n",
        "results_without_autoencoder[\"model\"] = results_without_autoencoder[\"model\"].astype('category')\n",
        "results_without_autoencoder[\"features\"] = results_without_autoencoder[\"features\"].astype('category')\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('\\nComparison of performance between the three ML algorithms')\n",
        "ax = sns.scatterplot(x=\"accuracy_train\", y=\"accuracy_test\", hue=\"model\", style=\"features\", s = 80, data=results_without_autoencoder)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.xlabel('Accuracy - Training Set')\n",
        "plt.ylabel('Accuracy - Testing Set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNqDzayzbnTg",
        "colab_type": "text"
      },
      "source": [
        "### Activity 3\n",
        "\n",
        "Based on the plot results, what combination of Model and Features do you think have the best results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL4xXfzomfiv",
        "colab_type": "text"
      },
      "source": [
        "### Activity 4 (Advanced Level)\n",
        "\n",
        "Now it's your turn to explore a classification model. \n",
        "\n",
        "There is classification model called [SVM](https://https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). After reading about this type of model, try to implement it by yourself! Before adding the outputs to the 'results' file, explore some of the parameters available as we did with KNN. Then, you can add your best SVM model in the 'results' file.\n",
        "\n",
        "Is part of this activity check the documentation and learn how to import and load the library with the function, and use it based on the documentation. :) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owuadnnMmpfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INSERT YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmDrkuNmpk_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INSERT YOUR CODE HERE TO COMPARE ALL THE MODELS ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdKi5OH_pLWw",
        "colab_type": "text"
      },
      "source": [
        "## 3. Convolutional Neural Network\n",
        "\n",
        "In the previous section, we explored classification models with the features we built yesterday.\n",
        "\n",
        "Now, we will explore one last model, called Convolutional Neural Network (CNN).\n",
        "We will not be using our feature set here. Instead, we will be using the original feature embeddings file given in the dataset.\n",
        "\n",
        "While the other models work for all types of inputs (images, tabular data, others), this CNN model receives the embeddings for only images. To use the CNN model, we will modify the format of the input data (embeddings file) a bit to fit the format of CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2fH2yU8ePqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will primarily be using the library 'keras' for most of our operations in CNN. Keras is an open-source deep learning/neural network library for Python.\n",
        "from keras.utils import np_utils #import all the numpy utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Dropping the column 'disease_condition' from embeddings01 so that we can focus on the embeddings for now\n",
        "temp = embeddings01.drop('disease_condition',axis=1)\n",
        "#Reshaping the dimensions of the embeddings from 2D to 3D vector (CNN requires 3D input)\n",
        "trainData = np.expand_dims(temp, axis=2)\n",
        "\n",
        "#Splitting into training data and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainData, target, test_size=0.3, random_state=7)\n",
        "\n",
        "# number of samples in training data\n",
        "print(\"Number of training samples:\", X_train.shape[0])\n",
        "# number of samples in testing data\n",
        "print(\"Number of testing samples:\", X_test.shape[0])\n",
        "# number of features used\n",
        "# this is the vector of features extracted \n",
        "print(\"Number of features:\", X_train.shape[1])\n",
        "\n",
        "#convert the train and test labels to np arrays\n",
        "y_train01=np.array(y_train)\n",
        "y_test01=np.array(y_test)\n",
        "\n",
        "print(y_train[0:5]) #print first five rows of y_train\n",
        "\n",
        "#Convert the array of labeled data to a one-hot vector, i.e. converting the array containing the labels 'active' and 'inactive' to a binary class matrix (0's and 1's).\n",
        "y_train = np_utils.to_categorical(y_train01)\n",
        "y_test = np_utils.to_categorical(y_test01)\n",
        "\n",
        "print(X_train.shape) #shape of training data\n",
        "print(y_train.shape) #shape of training labels\n",
        "print(X_test.shape) #shape of test data\n",
        "print(y_test.shape) #shape of test labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzpLaWsy3C-z",
        "colab_type": "text"
      },
      "source": [
        "We use keras library to build a sequential basic CNN model consisting of 4 convolutional layers and one fully connected layer at the end supported by softmax activation function for classification. Each convolutional layer is followed by a maxpool operation and a dropout layer.\n",
        "\n",
        "The code below is going to take a couple of minutes to run. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce44Wbr5piQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading libraries\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "from numpy import newaxis\n",
        "\n",
        "model = Sequential() #calling sequential before defining the layers helps to linearly stack the layers\n",
        "\n",
        "model.add(Conv1D(32,3,padding='same',activation='relu',input_shape=(1024,1))) #convolution layer\n",
        "model.add(MaxPooling1D(pool_size=2)) #max pool layer\n",
        "model.add(Dropout(0.1)) #dropout layer\n",
        "\n",
        "model.add(Conv1D(32,3,padding='same',activation='relu')) #convolution layer\n",
        "model.add(MaxPooling1D(pool_size=2)) #max pool layer\n",
        "model.add(Dropout(0.1)) #dropout layer\n",
        "\n",
        "model.add(Conv1D(64,3,padding='same',activation='relu')) #convolution layer\n",
        "model.add(MaxPooling1D(pool_size=2)) #max pool layer\n",
        "model.add(Dropout(0.1)) #dropout layer\n",
        "\n",
        "model.add(Conv1D(64,3,padding='same',activation='relu')) #convolution layer\n",
        "model.add(MaxPooling1D(pool_size=2)) #maxpool layer\n",
        "model.add(Flatten()) #Flatten is the function that converts the pooled feature map from maxpool to a single column that is passed to the fully connected layer.\n",
        "model.add(Dense(units=2,activation = 'softmax')) #Dense is the function that creates the fully connected layer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy']) #compile function configures a few parameters for training\n",
        "\n",
        "#Fit the model, train for 10 epochs, with batch size = 32\n",
        "cnnhistory=model.fit(X_train, np.array(y_train), batch_size=32, epochs=10, validation_data=(X_test, np.array(y_test)))\n",
        "\n",
        "#Print the training accuracy obtained in each epoch.\n",
        "print(\"\\nAccuracy: {:.2f}%\".format(cnnhistory.history['accuracy'][-1]*100))\n",
        "\n",
        "#Print the validation accuracy obtained in each epoch.\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(cnnhistory.history['val_accuracy'][-1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnVYeoarf4Lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.predict_classes is used to make the prediction for the training and test data\n",
        "y_train_pred = model.predict_classes(X_train) \n",
        "y_test_pred = model.predict_classes(X_test)\n",
        "\n",
        "output = {'model':'CNN', \n",
        "            'features':'embeddings', \n",
        "            'accuracy_train':accuracy_score(y_train01,y_train_pred), \n",
        "            'accuracy_test':accuracy_score(y_test01,y_test_pred), \n",
        "            'precision_test':precision_score(y_test01,y_test_pred) ,\n",
        "            'recall_test':recall_score(y_test01,y_test_pred) }\n",
        "\n",
        "#Let us make a prediction for the sample test image that we saw in the beginning.\n",
        "active_image_example = active_image_example.append({'model':'CNN', 'features':'embeddings', 'predicted_target':model.predict_classes(trainData[indice].reshape(1,1024,1))}, \n",
        "                              ignore_index=True)\n",
        "results = results.append(output,ignore_index=True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjhWdaXO__bB",
        "colab_type": "text"
      },
      "source": [
        "Let's check how each model predicted the results for the image we used above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdImDzqPADPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "active_image_example['predicted_target'] = ['inactive' if item==0 else 'active' for item in active_image_example['predicted_target']]\n",
        "\n",
        "active_image_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osYc_5vvFUzW",
        "colab_type": "text"
      },
      "source": [
        "It looks like all our models predicted this image correctly! :D "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqDAKy3ju6yF",
        "colab_type": "text"
      },
      "source": [
        "### Activity 5:\n",
        "\n",
        "Let us see if we can achieve the same accurate prediction when the CNN model has fewer layers, and is trained for fewer epochs.\n",
        "\n",
        "Create a CNN model consisting of just two layers and one fully connected layer by following the instructions given in the comments. Simply use the correct lines of code from the previous block for the correct layer. After building the model, train it for **5 epochs**. Then, run the code (already given) to print the training and validation accuracy, and to predict the class for the input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiN8_9yEv23U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential() \n",
        "\n",
        "#Insert a convolution layer, and a maxpool layer one after the other.\n",
        "\n",
        "\n",
        "#Insert a convolution layer, a maxpool layer, and a dropout layer one after the other.\n",
        "\n",
        "\n",
        "#Insert a convolution layer, a maxpool layer, a flatten layer, and a dense layer (fully connected layer) one after the other.\n",
        "\n",
        "\n",
        "#setting all the other parameters\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy']) \n",
        "\n",
        "#Insert code to fit the model, train for 5 epochs, with batch size = 32\n",
        "\n",
        "\n",
        "#Training accuracy obtained in each epoch.\n",
        "print(\"Accuracy: {:.2f}%\".format(cnnhistory.history['accuracy'][-1]*100))\n",
        "\n",
        "#Validation accuracy obtained in each epoch.\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(cnnhistory.history['val_accuracy'][-1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcyBFZhOxbW_",
        "colab_type": "text"
      },
      "source": [
        "Now that you have built your model successfully, trained and printed the training and validation accuracy per epoch, run the below code to print the overall training and test accuracy, and make a prediction for our sample test image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE4cInsUxYje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.predict_classes is used to make the prediction for the training and test data\n",
        "y_train_pred = model.predict_classes(X_train) \n",
        "y_test_pred = model.predict_classes(X_test)\n",
        "\n",
        "output = {'model':'CNN', \n",
        "            'features':'embeddings', \n",
        "            'accuracy_train':accuracy_score(y_train01,y_train_pred), \n",
        "            'accuracy_test':accuracy_score(y_test01,y_test_pred), \n",
        "            'precision_test':precision_score(y_test01,y_test_pred) ,\n",
        "            'recall_test':recall_score(y_test01,y_test_pred)  }\n",
        "\n",
        "active_image_example = active_image_example.append({'model':'myCNN', 'features':'embeddings', 'predicted_target':model.predict_classes(trainData[indice].reshape(1,1024,1))}, \n",
        "                              ignore_index=True)\n",
        "results = results.append(output,ignore_index=True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRjgzwxu4sM2",
        "colab_type": "text"
      },
      "source": [
        "Now, let us view the prediction made by the model you just built, along with the predictions made by all the other models we used till now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOd05yQF46Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "active_image_example['predicted_target'] = ['inactive' if item==0 else 'active' for item in active_image_example['predicted_target']]\n",
        "\n",
        "active_image_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsB0D-rxlvoG",
        "colab_type": "text"
      },
      "source": [
        "### Activity 6:\n",
        " \n",
        "Create two plots to compare the previously explored models (CNN, KNN, LR, RF, others).\n",
        "\n",
        "1. Accuracy on training data *versus* testing data; \n",
        "2. Precision *versus* Recall on testing data. \n",
        "\n",
        "Given a set of unlabelled cell images, if you had to choose only one model to classify if they are infected (label ‘active’) by SARS-CoV-2 or not (label ‘inactive’), which one would be? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXLqma59sKUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INSERT YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
